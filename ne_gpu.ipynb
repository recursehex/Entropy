{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "# Check if CUDA is available and set the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# If using CUDA, print some additional information\n",
    "if device.type == 'cuda':\n",
    "    print(f\"Device name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Device memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    # Set default tensor type to cuda\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "def generate_skewed_gaussian(age, mu, std, p_center):\n",
    "    z = (age - mu) / std\n",
    "    base_prob = p_center * np.exp(-0.5 * z ** 2)\n",
    "    if age > mu:\n",
    "        skew_factor = 1 + 0.15 * (z ** 2)\n",
    "        base_prob *= skew_factor\n",
    "    return min(base_prob, 1.0)\n",
    "\n",
    "class MedicalDataset(Dataset):\n",
    "    def __init__(self, ages, condition_ids, labels, true_probs, age_mean, age_std):\n",
    "        self.ages = torch.FloatTensor((ages - age_mean) / age_std).reshape(-1, 1)\n",
    "        self.condition_ids = torch.LongTensor(condition_ids)\n",
    "        self.labels = torch.FloatTensor(labels).reshape(-1, 1)\n",
    "        self.true_probs = torch.FloatTensor(true_probs).reshape(-1, 1)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ages)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (self.ages[idx], self.condition_ids[idx]), self.labels[idx], self.true_probs[idx]\n",
    "\n",
    "class ProbabilityNN(nn.Module):\n",
    "    def __init__(self, num_conditions, embedding_dim=16, hidden_dim=128, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        self.condition_embedding = nn.Embedding(num_conditions, embedding_dim)\n",
    "        input_size = 1 + embedding_dim\n",
    "        \n",
    "        # Enhanced network with more capacity and residual connections\n",
    "        self.input_layer = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        \n",
    "        self.hidden_layer1 = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        \n",
    "        self.hidden_layer2 = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        \n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        age, condition_id = x\n",
    "        condition_emb = self.condition_embedding(condition_id)\n",
    "        combined_input = torch.cat([age, condition_emb], dim=1)\n",
    "        \n",
    "        x = self.input_layer(combined_input)\n",
    "        \n",
    "        # Residual connection 1\n",
    "        res1 = x\n",
    "        x = self.hidden_layer1(x)\n",
    "        x = x + res1  # Residual connection\n",
    "        \n",
    "        # Residual connection 2\n",
    "        res2 = x\n",
    "        x = self.hidden_layer2(x)\n",
    "        x = x + res2  # Residual connection\n",
    "        \n",
    "        return self.output_layer(x)\n",
    "\n",
    "def combined_loss(predictions, labels, true_probs, condition_ids, condition_medians, condition_quartiles, alpha=0.5, beta=0.3, gamma=0.2):\n",
    "    \"\"\"\n",
    "    Combined loss function with:\n",
    "    1. Normalized entropy loss using condition-specific medians\n",
    "    2. Distribution matching loss (MSE between predicted and true probabilities)\n",
    "    3. Shape preservation loss based on quartile differences\n",
    "    \"\"\"\n",
    "    eps = 1e-7\n",
    "    predictions = torch.clamp(predictions, eps, 1 - eps)\n",
    "    \n",
    "    # Get the median probabilities for each sample based on its condition ID\n",
    "    batch_medians = torch.tensor([condition_medians[cid.item()] for cid in condition_ids], \n",
    "                                device=predictions.device).reshape(-1, 1)\n",
    "    \n",
    "    # 1. Normalized Entropy Loss\n",
    "    ce = -labels * torch.log2(predictions) - (1 - labels) * torch.log2(1 - predictions)\n",
    "    ne_denominator = -labels * torch.log2(batch_medians) - (1 - labels) * torch.log2(1 - batch_medians)\n",
    "    ne_loss = ce.sum() / ne_denominator.sum()\n",
    "    \n",
    "    # 2. Distribution Matching Loss (MSE between predicted and true probabilities)\n",
    "    dist_loss = torch.mean((predictions - true_probs) ** 2)\n",
    "    \n",
    "    # 3. Shape Preservation Loss\n",
    "    # For each condition, ensure the shape is preserved by penalizing deviation from expected quartile differences\n",
    "    shape_loss = 0.0\n",
    "    for cid in range(len(condition_quartiles)):\n",
    "        condition_mask = (condition_ids == cid)\n",
    "        if condition_mask.sum() > 0:\n",
    "            cond_preds = predictions[condition_mask]\n",
    "            \n",
    "            # Safely handle empty tensors or small batches\n",
    "            if cond_preds.numel() > 3:\n",
    "                cond_pred_quartiles = torch.tensor([\n",
    "                    torch.quantile(cond_preds.flatten(), 0.25),\n",
    "                    torch.quantile(cond_preds.flatten(), 0.5),\n",
    "                    torch.quantile(cond_preds.flatten(), 0.75)\n",
    "                ], device=predictions.device)\n",
    "            else:\n",
    "                # Use mean as approximation if not enough data points\n",
    "                cond_pred_quartiles = torch.tensor([\n",
    "                    torch.mean(cond_preds) * 0.8,\n",
    "                    torch.mean(cond_preds),\n",
    "                    torch.mean(cond_preds) * 1.2\n",
    "                ], device=predictions.device)\n",
    "            \n",
    "            # Calculate predicted inter-quartile differences\n",
    "            pred_q_diffs = cond_pred_quartiles[1:] - cond_pred_quartiles[:-1]\n",
    "            \n",
    "            # Compare with true inter-quartile differences\n",
    "            q_array = np.array(condition_quartiles[cid])\n",
    "            true_q_diffs = q_array[1:] - q_array[:-1]\n",
    "            true_q_diffs = torch.tensor(true_q_diffs, device=pred_q_diffs.device)\n",
    "            \n",
    "            # Normalize the differences to make it scale-invariant\n",
    "            norm_factor = true_q_diffs.abs().sum()\n",
    "            if norm_factor > 1e-6:  # Prevent division by very small numbers\n",
    "                shape_loss += torch.sum(torch.abs(pred_q_diffs - true_q_diffs)) / norm_factor\n",
    "            else:\n",
    "                # If all quartiles are the same, just penalize any deviation\n",
    "                shape_loss += torch.sum(torch.abs(pred_q_diffs))\n",
    "    \n",
    "    # Combine the losses\n",
    "    total_loss = alpha * ne_loss + beta * dist_loss + gamma * shape_loss\n",
    "    \n",
    "    return total_loss, ne_loss, dist_loss, shape_loss\n",
    "\n",
    "def main(mu_list=None, std_list=None, p_center_list=None,\n",
    "         embedding_dim=16, hidden_dim=128, n_epochs=30, batch_size=1000, train_split=0.9, \n",
    "         learning_rate=0.01, alpha=0.5, beta=0.3, gamma=0.2):\n",
    "    # Set default parameters if none provided\n",
    "    if mu_list is None:\n",
    "        mu_list = [30, 40, 50, 60, 70]\n",
    "    if std_list is None:\n",
    "        std_list = [5, 2, 4, 6, 8]\n",
    "    if p_center_list is None:\n",
    "        p_center_list = [0.15, 0.02, 0.15, 0.08, 0.12]\n",
    "    \n",
    "    # Determine number of conditions from parameter lengths\n",
    "    K = len(mu_list)\n",
    "    T = int(100000 / K)\n",
    "    TOTAL_SAMPLES = T * K\n",
    "\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Set CUDA seed if available\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(42)\n",
    "        torch.cuda.manual_seed_all(42)  # if using multi-GPU\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # Pre-allocate arrays for dataset\n",
    "    all_ages = np.zeros(TOTAL_SAMPLES, dtype=np.int32)\n",
    "    all_condition_ids = np.zeros(TOTAL_SAMPLES, dtype=np.int32)\n",
    "    all_labels = np.zeros(TOTAL_SAMPLES, dtype=np.int32)\n",
    "    all_true_probs = np.zeros(TOTAL_SAMPLES, dtype=np.float32)\n",
    "\n",
    "    for condition_id in range(K):\n",
    "        start_idx = condition_id * T\n",
    "        end_idx = (condition_id + 1) * T\n",
    "        ages = np.random.randint(1, 101, size=T)\n",
    "        probabilities = np.array([\n",
    "            generate_skewed_gaussian(age, mu_list[condition_id], std_list[condition_id], p_center_list[condition_id])\n",
    "            for age in ages\n",
    "        ])\n",
    "        labels = np.random.binomial(n=1, p=probabilities)\n",
    "        all_ages[start_idx:end_idx] = ages\n",
    "        all_condition_ids[start_idx:end_idx] = condition_id\n",
    "        all_labels[start_idx:end_idx] = labels\n",
    "        all_true_probs[start_idx:end_idx] = probabilities\n",
    "\n",
    "    # Compute statistics for each condition\n",
    "    condition_medians = []\n",
    "    condition_quartiles = []\n",
    "    \n",
    "    for condition_id in range(K):\n",
    "        condition_mask = all_condition_ids == condition_id\n",
    "        condition_probs = all_true_probs[condition_mask]\n",
    "        \n",
    "        # Calculate median\n",
    "        median_prob = np.median(condition_probs)\n",
    "        condition_medians.append(median_prob)\n",
    "        \n",
    "        # Calculate quartiles for shape preservation\n",
    "        q1 = np.quantile(condition_probs, 0.25)\n",
    "        q2 = median_prob  # median is already the 50th percentile\n",
    "        q3 = np.quantile(condition_probs, 0.75)\n",
    "        # Store as numpy array instead of list\n",
    "        condition_quartiles.append(np.array([q1, q2, q3]))\n",
    "        \n",
    "        print(f\"Condition {condition_id} statistics:\")\n",
    "        print(f\"  Median probability: {median_prob:.4f}\")\n",
    "        print(f\"  Q1: {q1:.4f}, Q3: {q3:.4f}\")\n",
    "        print(f\"  IQR: {q3-q1:.4f}\")\n",
    "    \n",
    "    condition_medians = np.array(condition_medians)\n",
    "    \n",
    "    # Move condition_medians to device\n",
    "    condition_medians_tensor = torch.tensor(condition_medians, device=device)\n",
    "\n",
    "    # Normalize ages\n",
    "    age_mean = np.mean(all_ages)\n",
    "    age_std = np.std(all_ages)\n",
    "\n",
    "    # Plot true probability distributions for each condition\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    age_range = np.arange(1, 101)\n",
    "    for condition_id in range(K):\n",
    "        true_probs = [generate_skewed_gaussian(age, mu_list[condition_id],\n",
    "                                                 std_list[condition_id],\n",
    "                                                 p_center_list[condition_id])\n",
    "                      for age in age_range]\n",
    "        plt.plot(age_range, true_probs, label=f'Condition {condition_id}')\n",
    "        \n",
    "        # Add lines for quartiles\n",
    "        q1, q2, q3 = condition_quartiles[condition_id]\n",
    "        plt.axhline(y=q1, color=f'C{condition_id}', linestyle=':', alpha=0.3)\n",
    "        plt.axhline(y=q2, color=f'C{condition_id}', linestyle='--', alpha=0.5, \n",
    "                   label=f'Median Condition {condition_id}')\n",
    "        plt.axhline(y=q3, color=f'C{condition_id}', linestyle=':', alpha=0.3)\n",
    "    \n",
    "    plt.xlabel('Age')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.title('True Probability Distributions for Each Condition with Medians and Quartiles')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Prepare data loaders with true probabilities\n",
    "    dataset = MedicalDataset(all_ages, all_condition_ids, all_labels, all_true_probs, age_mean, age_std)\n",
    "    \n",
    "    # Use a generator with fixed seed for reproducibility\n",
    "    generator = torch.Generator().manual_seed(42)\n",
    "    train_size = int(train_split * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size], generator=generator)\n",
    "    \n",
    "    # Set pin_memory=True for faster data transfer to GPU\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=torch.cuda.is_available())\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "    # Initialize model, optimizer, scheduler\n",
    "    model = ProbabilityNN(num_conditions=K, embedding_dim=embedding_dim, hidden_dim=hidden_dim)\n",
    "    # Move model to GPU if available\n",
    "    model = model.to(device)\n",
    "    \n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer, max_lr=learning_rate, \n",
    "        steps_per_epoch=len(train_loader), \n",
    "        epochs=n_epochs\n",
    "    )\n",
    "\n",
    "    # Training and validation loss tracking\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    train_losses = {'total': [], 'ne': [], 'dist': [], 'shape': []}\n",
    "    val_losses = {'total': [], 'ne': [], 'dist': [], 'shape': []}\n",
    "\n",
    "    print(f\"Starting training with alpha={alpha}, beta={beta}, gamma={gamma}\")\n",
    "    \n",
    "    # Add timing for performance comparison\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        epoch_losses = {'total': [], 'ne': [], 'dist': [], 'shape': []}\n",
    "        epoch_start_time = time.time()\n",
    "        \n",
    "        for (age_batch, condition_batch), target_batch, true_prob_batch in train_loader:\n",
    "            # Move data to device\n",
    "            age_batch, condition_batch = age_batch.to(device), condition_batch.to(device)\n",
    "            target_batch, true_prob_batch = target_batch.to(device), true_prob_batch.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model((age_batch, condition_batch))\n",
    "            \n",
    "            loss, ne_loss, dist_loss, shape_loss = combined_loss(\n",
    "                output, target_batch, true_prob_batch, condition_batch, \n",
    "                condition_medians_tensor, condition_quartiles,\n",
    "                alpha, beta, gamma\n",
    "            )\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            epoch_losses['total'].append(loss.item())\n",
    "            epoch_losses['ne'].append(ne_loss.item())\n",
    "            epoch_losses['dist'].append(dist_loss.item())\n",
    "            epoch_losses['shape'].append(shape_loss.item())\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_epoch_losses = {'total': 0, 'ne': 0, 'dist': 0, 'shape': 0}\n",
    "        val_batches = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for (age_batch, condition_batch), target_batch, true_prob_batch in test_loader:\n",
    "                # Move data to device\n",
    "                age_batch, condition_batch = age_batch.to(device), condition_batch.to(device)\n",
    "                target_batch, true_prob_batch = target_batch.to(device), true_prob_batch.to(device)\n",
    "                \n",
    "                output = model((age_batch, condition_batch))\n",
    "                \n",
    "                val_loss, val_ne, val_dist, val_shape = combined_loss(\n",
    "                    output, target_batch, true_prob_batch, condition_batch,\n",
    "                    condition_medians_tensor, condition_quartiles,\n",
    "                    alpha, beta, gamma\n",
    "                )\n",
    "                \n",
    "                val_epoch_losses['total'] += val_loss.item()\n",
    "                val_epoch_losses['ne'] += val_ne.item()\n",
    "                val_epoch_losses['dist'] += val_dist.item()\n",
    "                val_epoch_losses['shape'] += val_shape.item()\n",
    "                val_batches += 1\n",
    "        \n",
    "        # Average losses\n",
    "        for key in val_epoch_losses:\n",
    "            val_epoch_losses[key] /= val_batches\n",
    "            train_losses[key].append(np.mean(epoch_losses[key]))\n",
    "            val_losses[key].append(val_epoch_losses[key])\n",
    "        \n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        \n",
    "        # Print progress\n",
    "        if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "            print(f'Epoch {epoch + 1}/{n_epochs}: {epoch_time:.2f}s')\n",
    "            print(f'  Training Loss: {train_losses[\"total\"][-1]:.4f} (NE: {train_losses[\"ne\"][-1]:.4f}, '\n",
    "                  f'Dist: {train_losses[\"dist\"][-1]:.4f}, Shape: {train_losses[\"shape\"][-1]:.4f})')\n",
    "            print(f'  Validation Loss: {val_losses[\"total\"][-1]:.4f} (NE: {val_losses[\"ne\"][-1]:.4f}, '\n",
    "                  f'Dist: {val_losses[\"dist\"][-1]:.4f}, Shape: {val_losses[\"shape\"][-1]:.4f})')\n",
    "            print(f'  Learning Rate: {scheduler.get_last_lr()[0]:.6f}\\n')\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nTotal training time: {total_time:.2f}s, Average epoch time: {total_time/n_epochs:.2f}s\")\n",
    "\n",
    "    # Plot training progress\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(train_losses['total'], label='Training Total Loss')\n",
    "    plt.plot(val_losses['total'], label='Validation Total Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Total Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(train_losses['ne'], label='Training NE Loss')\n",
    "    plt.plot(val_losses['ne'], label='Validation NE Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Normalized Entropy Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(train_losses['dist'], label='Training Dist Loss')\n",
    "    plt.plot(val_losses['dist'], label='Validation Dist Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Distribution Matching Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.plot(train_losses['shape'], label='Training Shape Loss')\n",
    "    plt.plot(val_losses['shape'], label='Validation Shape Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Shape Preservation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot predictions vs true probabilities\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    age_range_tensor = torch.FloatTensor((np.arange(1, 101) - age_mean) / age_std).reshape(-1, 1).to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Create a grid of plots for each condition\n",
    "    for condition_id in range(K):\n",
    "        plt.subplot(3, 2, condition_id + 1)\n",
    "        \n",
    "        condition_ids = torch.full((100,), condition_id, dtype=torch.long).to(device)\n",
    "        with torch.no_grad():\n",
    "            predictions = model((age_range_tensor, condition_ids))\n",
    "            # Move predictions back to CPU for plotting\n",
    "            predictions = predictions.cpu()\n",
    "        \n",
    "        true_probs = [generate_skewed_gaussian(age, mu_list[condition_id],\n",
    "                                               std_list[condition_id],\n",
    "                                               p_center_list[condition_id])\n",
    "                      for age in range(1, 101)]\n",
    "        \n",
    "        plt.plot(range(1, 101), true_probs, label=f'True', color='blue', linestyle='-')\n",
    "        plt.plot(range(1, 101), predictions.numpy(), label=f'Predicted', color='red', linestyle='--')\n",
    "        \n",
    "        # Add quartile lines\n",
    "        q1, q2, q3 = condition_quartiles[condition_id]\n",
    "        plt.axhline(y=q1, color='blue', linestyle=':', alpha=0.3)\n",
    "        plt.axhline(y=q2, color='blue', linestyle='--', alpha=0.5, label='True Median')\n",
    "        plt.axhline(y=q3, color='blue', linestyle=':', alpha=0.3)\n",
    "        \n",
    "        # Add predicted quartiles\n",
    "        pred_q1 = np.quantile(predictions.numpy(), 0.25)\n",
    "        pred_q2 = np.quantile(predictions.numpy(), 0.5)\n",
    "        pred_q3 = np.quantile(predictions.numpy(), 0.75)\n",
    "        plt.axhline(y=pred_q1, color='red', linestyle=':', alpha=0.3)\n",
    "        plt.axhline(y=pred_q2, color='red', linestyle='--', alpha=0.5, label='Pred Median')\n",
    "        plt.axhline(y=pred_q3, color='red', linestyle=':', alpha=0.3)\n",
    "        \n",
    "        plt.xlabel('Age')\n",
    "        plt.ylabel('Probability')\n",
    "        plt.title(f'Condition {condition_id}: True vs Predicted Distribution')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print final statistics\n",
    "    print(\"\\nFinal Distribution Alignment Statistics:\")\n",
    "    for condition_id in range(K):\n",
    "        condition_ids = torch.full((100,), condition_id, dtype=torch.long).to(device)\n",
    "        with torch.no_grad():\n",
    "            predictions = model((age_range_tensor, condition_ids))\n",
    "            # Move back to CPU for numpy operations\n",
    "            predictions = predictions.cpu()\n",
    "        \n",
    "        true_probs = np.array([\n",
    "            generate_skewed_gaussian(age, mu_list[condition_id], std_list[condition_id], p_center_list[condition_id])\n",
    "            for age in range(1, 101)\n",
    "        ])\n",
    "        \n",
    "        pred_probs = predictions.numpy().flatten()\n",
    "        \n",
    "        # Calculate statistics\n",
    "        true_median = np.median(true_probs)\n",
    "        pred_median = np.median(pred_probs)\n",
    "        true_q1 = np.quantile(true_probs, 0.25)\n",
    "        pred_q1 = np.quantile(pred_probs, 0.25)\n",
    "        true_q3 = np.quantile(true_probs, 0.75)\n",
    "        pred_q3 = np.quantile(pred_probs, 0.75)\n",
    "        \n",
    "        # MSE between distributions\n",
    "        mse = np.mean((true_probs - pred_probs) ** 2)\n",
    "        \n",
    "        print(f\"Condition {condition_id}:\")\n",
    "        print(f\"  MSE: {mse:.6f}\")\n",
    "        print(f\"  True Median: {true_median:.4f}, Predicted Median: {pred_median:.4f}, Diff: {abs(true_median-pred_median):.4f}\")\n",
    "        print(f\"  True Q1: {true_q1:.4f}, Predicted Q1: {pred_q1:.4f}, Diff: {abs(true_q1-pred_q1):.4f}\")\n",
    "        print(f\"  True Q3: {true_q3:.4f}, Predicted Q3: {pred_q3:.4f}, Diff: {abs(true_q3-pred_q3):.4f}\")\n",
    "        print(f\"  True IQR: {true_q3-true_q1:.4f}, Predicted IQR: {pred_q3-pred_q1:.4f}\")\n",
    "        print()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
