{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 1000\n",
      "Training samples: 800\n",
      "Evaluation samples: 200\n",
      "\n",
      "Example training samples:\n",
      "  X=[2.0, 34.427040100097656]  y=1\n",
      "  X=[2.0, 27.55743980407715]  y=0\n",
      "  X=[0.0, 16.924644470214844]  y=1\n",
      "  X=[1.0, 22.798748016357422]  y=1\n",
      "  X=[3.0, 42.41710662841797]  y=1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "###############################################################################\n",
    "# 1. Set up parameters for ads and their age distributions\n",
    "###############################################################################\n",
    "\n",
    "# We'll generate N_PER_AD samples for each of 5 ads.\n",
    "N_PER_AD = 200\n",
    "ad_ids = [0, 1, 2, 3, 4]  \n",
    "\n",
    "# For each ad, we'll define a different normal distribution for the user's age.\n",
    "# (You can customize the means/stddevs as desired.)\n",
    "age_distributions = {\n",
    "    0: {\"mean\": 20.0, \"std\": 4.0},\n",
    "    1: {\"mean\": 25.0, \"std\": 5.0},\n",
    "    2: {\"mean\": 30.0, \"std\": 6.0},\n",
    "    3: {\"mean\": 45.0, \"std\": 5.0},\n",
    "    4: {\"mean\": 50.0, \"std\": 6.0},\n",
    "}\n",
    "\n",
    "# Define a \"true\" logistic function that depends on ad_id and age.\n",
    "# For example:  logit = -2.0 + 0.5 * ad_id + 0.05 * age\n",
    "TRUE_BIAS = -2.0\n",
    "TRUE_WEIGHT_AD_ID = 0.5\n",
    "TRUE_WEIGHT_AGE = 0.05\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 2. Generate the synthetic samples for each ad\n",
    "###############################################################################\n",
    "\n",
    "all_ad_ids = []\n",
    "all_ages = []\n",
    "all_labels = []\n",
    "\n",
    "for ad_id in ad_ids:\n",
    "    dist_params = age_distributions[ad_id]\n",
    "    \n",
    "    # 2a. Generate random ages for this ad\n",
    "    # We'll clamp ages to [0, 100] just to avoid negative or unrealistic extremes.\n",
    "    ages = torch.normal(mean=dist_params[\"mean\"], \n",
    "                        std=dist_params[\"std\"], \n",
    "                        size=(N_PER_AD,))\n",
    "    ages = torch.clamp(ages, min=0.0, max=100.0)\n",
    "    \n",
    "    # 2b. Create a tensor of ad IDs matching the shape of ages\n",
    "    ad_id_tensor = torch.full((N_PER_AD,), float(ad_id))\n",
    "    \n",
    "    # 2c. Calculate the \"true\" logit for each sample\n",
    "    logits = (TRUE_BIAS\n",
    "              + TRUE_WEIGHT_AD_ID * ad_id_tensor\n",
    "              + TRUE_WEIGHT_AGE * ages)\n",
    "    \n",
    "    # 2d. Convert logits to probabilities via sigmoid\n",
    "    prob = torch.sigmoid(logits)\n",
    "    \n",
    "    # 2e. Sample a label (0 or 1) from a Bernoulli distribution with parameter prob\n",
    "    labels = (torch.rand(N_PER_AD) < prob).float()\n",
    "    \n",
    "    # 2f. Append to lists\n",
    "    all_ad_ids.append(ad_id_tensor)\n",
    "    all_ages.append(ages)\n",
    "    all_labels.append(labels)\n",
    "\n",
    "# Concatenate all samples across the 5 ads\n",
    "ad_ids_combined = torch.cat(all_ad_ids)  # shape [5*N_PER_AD]\n",
    "ages_combined   = torch.cat(all_ages)    # shape [5*N_PER_AD]\n",
    "y_combined      = torch.cat(all_labels)  # shape [5*N_PER_AD]\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 3. Build final feature matrix X = [ad_id, age], shuffle, and split\n",
    "###############################################################################\n",
    "\n",
    "# Stack into a single tensor of shape [N, 2]\n",
    "X_combined = torch.stack([ad_ids_combined, ages_combined], dim=1)\n",
    "\n",
    "# We want to unify labels into shape [N, 1] for convenience\n",
    "y_combined = y_combined.view(-1, 1)\n",
    "\n",
    "# Shuffle the dataset indices\n",
    "N = X_combined.size(0)  # total number of samples (should be 5*N_PER_AD)\n",
    "indices = torch.randperm(N)\n",
    "\n",
    "# Apply the shuffle\n",
    "X_shuffled = X_combined[indices]\n",
    "y_shuffled = y_combined[indices]\n",
    "\n",
    "# Choose a split ratio, e.g. 80% train, 20% eval\n",
    "train_ratio = 0.8\n",
    "train_size = int(train_ratio * N)\n",
    "\n",
    "# Split into train and eval\n",
    "X_train = X_shuffled[:train_size]\n",
    "y_train = y_shuffled[:train_size]\n",
    "X_eval  = X_shuffled[train_size:]\n",
    "y_eval  = y_shuffled[train_size:]\n",
    "\n",
    "###############################################################################\n",
    "# 4. Print summary\n",
    "###############################################################################\n",
    "\n",
    "print(\"Total samples:\", N)\n",
    "print(\"Training samples:\", X_train.size(0))\n",
    "print(\"Evaluation samples:\", X_eval.size(0))\n",
    "\n",
    "# Just to get a sense of what we've got:\n",
    "print(\"\\nExample training samples:\")\n",
    "for i in range(5):\n",
    "    print(f\"  X={X_train[i].tolist()}  y={y_train[i].item():.0f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
